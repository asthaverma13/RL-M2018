{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Policy for player\n",
    "def target_policy_player(pl_ace_flag, pl_sum, dl_card):\n",
    "    return pl_policy[pl_sum]\n",
    "# Random behaviour Policy for player\n",
    "def behavior_policy_player(pl_ace_flag, pl_sum, dl_card):\n",
    "    if np.random.binomial(1, 0.5) == 1:\n",
    "        return stand\n",
    "    return hit\n",
    "# draw card from the Deck.\n",
    "def drawCard():\n",
    "    card = np.random.randint(1, 13)\n",
    "    if card > 10:\n",
    "        card = 10    \n",
    "    return card\n",
    "# Game \n",
    "def blackjack(policy_player, initial_state=None, initial_action=None):\n",
    "    pl_sum = 0\n",
    "    pl_history = []\n",
    "    pl_ace_flag = False # True --> player use ace as 11 otherwise 1\n",
    "    dl_card1 = 0\n",
    "    dl_card2 = 0\n",
    "    dl_ace_flag = False\n",
    "    if initial_state is None:\n",
    "        n_ace = 0\n",
    "        while pl_sum < 12:\n",
    "            card = drawCard()\n",
    "            if card == 1:\n",
    "                n_ace += 1\n",
    "                card = 11\n",
    "                pl_ace_flag = True\n",
    "            pl_sum += card\n",
    "        if pl_sum > 21:\n",
    "            pl_sum -= 10\n",
    "            if n_ace == 1:\n",
    "                pl_ace_flag = False\n",
    "        #get dealer cards\n",
    "        dl_card1 = drawCard()\n",
    "        dl_card2 = drawCard()\n",
    "    else:\n",
    "        pl_ace_flag, pl_sum, dl_card1 = initial_state\n",
    "        dl_card2 = drawCard()\n",
    "\n",
    "    state = [pl_ace_flag, pl_sum, dl_card1]\n",
    "        \n",
    "    \n",
    "    dl_sum = 0\n",
    "    if dl_card1 == 1 and dl_card2 != 1:\n",
    "        dl_sum += 11 + dl_card2\n",
    "        dl_ace_flag = True\n",
    "    elif dl_card1 != 1 and dl_card2 == 1:\n",
    "        dl_sum += dl_card1 + 11\n",
    "        dl_ace_flag = True\n",
    "    elif dl_card1 == 1 and dl_card2 == 1:\n",
    "        dl_sum += 1 + 11\n",
    "        dl_ace_flag = True\n",
    "    else:\n",
    "        dl_sum += dl_card1 + dl_card2\n",
    "   \n",
    "    while True:\n",
    "        if initial_action is not None:\n",
    "            action = initial_action\n",
    "            initial_action = None\n",
    "        else:\n",
    "            action = policy_player(pl_ace_flag, pl_sum, dl_card1)\n",
    "        pl_history.append([(pl_ace_flag, pl_sum, dl_card1), action])\n",
    "\n",
    "        if action == stand:\n",
    "            break\n",
    "         # HIT   \n",
    "        pl_sum += drawCard()\n",
    "        # BUSTS\n",
    "        if pl_sum > 21:\n",
    "            #  Avoid busting\n",
    "            if pl_ace_flag == True:\n",
    "                pl_sum -= 10\n",
    "                pl_ace_flag = False\n",
    "            else:\n",
    "                # Player loses\n",
    "                return state, -1, pl_history\n",
    "    # dealer's turn\n",
    "    while True:\n",
    "        # get action based on current sum\n",
    "        action = dl_policy[dl_sum]\n",
    "        if action == stand:\n",
    "            break\n",
    "        # HIT\n",
    "        new_card = drawCard()\n",
    "        if new_card == 1 and dl_sum + 11 < 21:\n",
    "            dl_sum += 11\n",
    "            dl_ace_flag = True\n",
    "        else:\n",
    "            dl_sum += new_card\n",
    "        # BUST\n",
    "        if dl_sum > 21:\n",
    "            if dl_ace_flag == True:\n",
    "            #  Avoid busting and continue\n",
    "                dl_sum -= 10\n",
    "                dl_ace_flag = False\n",
    "            else:\n",
    "            # otherwise dealer loses\n",
    "                return state, 1, pl_history\n",
    "     # compare the sum between player and dealer\n",
    "    if pl_sum > dl_sum:\n",
    "        return state, 1, pl_history\n",
    "    elif pl_sum == dl_sum:\n",
    "        return state, 0, pl_history\n",
    "    else:\n",
    "        return state, -1, pl_history\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def MS_ES(episodes):\n",
    "    state_action_values = np.zeros((10, 10, 2, 2))\n",
    "    state_action_pair_count = np.ones((10, 10, 2, 2))\n",
    "    def behavior_policy(usable_ace, player_sum, dealer_card):\n",
    "        usable_ace = int(usable_ace)\n",
    "        player_sum -= 12\n",
    "        dealer_card -= 1\n",
    "        #action = int(action)\n",
    "        values_ = state_action_values[player_sum, dealer_card, usable_ace, :] / \\\n",
    "                  state_action_pair_count[player_sum, dealer_card, usable_ace, :]\n",
    "        return np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)])\n",
    "    for episode in range(episodes):\n",
    "        # Random State\n",
    "        initial_state = [bool(np.random.choice([0, 1])),np.random.choice(range(12, 22)),np.random.choice(range(1, 11))]\n",
    "        initial_action = np.random.choice(actions) # Random Action\n",
    "        current_policy = behavior_policy if episode else target_policy_player # Get the current policy\n",
    "        _, reward, trajectory = blackjack(current_policy, initial_state, initial_action)\n",
    "        for (usable_ace, player_sum, dealer_card), action in trajectory:\n",
    "            usable_ace = int(usable_ace)\n",
    "            player_sum -= 12\n",
    "            dealer_card -= 1\n",
    "            action = int(action)\n",
    "            state_action_values[player_sum, dealer_card, usable_ace, action] += reward #Update state action Values\n",
    "            state_action_pair_count[player_sum, dealer_card, usable_ace, action] += 1\n",
    "\n",
    "    return state_action_values / state_action_pair_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Actions\n",
    "hit= 0\n",
    "stand = 1\n",
    "actions = [hit,stand]\n",
    "# The Policy that Sticks if the player's sum is 20 or 21 and hit othewise\n",
    "pl_policy = np.zeros(22)\n",
    "for i in range(12, 20):\n",
    "    pl_policy[i] = hit\n",
    "pl_policy[20] = stand\n",
    "pl_policy[21] = stand\n",
    "# Dealer hits and sticks according to a fixed stratergy without choice: \n",
    "dl_policy = np.zeros(22)\n",
    "for i in range(12, 17): \n",
    "    dl_policy[i] = hit\n",
    "for i in range(17, 22):\n",
    "    dl_policy[i] = stand # sticks on any sum of 17 or greater\n",
    "state_action_values = MS_ES(500000) # Run Monte carlo for 500000 Episodes\n",
    "state_value_no_usable_ace = np.max(state_action_values[:, :, 0, :], axis=-1)\n",
    "state_value_usable_ace = np.max(state_action_values[:, :, 1, :], axis=-1)\n",
    "# get the optimal policy\n",
    "action_no_usable_ace = np.argmax(state_action_values[:, :, 0, :], axis=-1)\n",
    "action_usable_ace = np.argmax(state_action_values[:, :, 1, :], axis=-1)\n",
    "images1 = [state_value_usable_ace,state_value_no_usable_ace]\n",
    "titles1 = ['Optimal value with usable Ace','Optimal value without usable Ace']\n",
    "index = [1,2]\n",
    "fig = plt.figure(figsize=plt.figaspect(1))\n",
    "for image, title, a in zip(images1, titles1, index):\n",
    "    ax = fig.add_subplot(2, 1, a, projection='3d')\n",
    "    surf = ax.plot_surface(range(1,11), range(12,22), image, rstride=1, cstride=1, cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "    ax.set_zlim(-1.01, 1.01)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "    plt.ylabel('player sum', fontsize=10)\n",
    "    plt.xlabel('dealer showing', fontsize=10)\n",
    "    plt.title(title, fontsize=10)\n",
    "\n",
    "plt.savefig('5_2.png')\n",
    "plt.close()\n",
    "\n",
    "images2 = [action_usable_ace, action_no_usable_ace]\n",
    "titles2 = ['Optimal policy with usable Ace', 'Optimal policy without usable Ace']\n",
    "_, axes = plt.subplots(2, 1, figsize=(40, 30))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for image, title, axis in zip(images2, titles2, axes):\n",
    "    fig = sns.heatmap(np.flipud(image), cmap=\"YlGnBu\", ax=axis, xticklabels=range(1, 11),\n",
    "                      yticklabels=list(reversed(range(12, 22))))\n",
    "    fig.set_ylabel('player sum', fontsize=30)\n",
    "    fig.set_xlabel('dealer showing', fontsize=30)\n",
    "    fig.set_title(title, fontsize=30)\n",
    "\n",
    "plt.savefig('figure_5_2.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
